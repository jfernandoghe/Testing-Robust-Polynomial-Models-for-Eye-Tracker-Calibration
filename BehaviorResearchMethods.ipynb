{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BehaviorResearchMethods.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ZGLYkEvnCp25"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jfernandoghe/Testing-Robust-Polynomial-Models-for-Eye-Tracker-Calibration/blob/master/BehaviorResearchMethods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGLYkEvnCp25",
        "colab_type": "text"
      },
      "source": [
        "## Download dataset from Dryad website [https://doi.org/10.5061/dryad.3ts56](https://datadryad.org/stash/dataset/doi:10.5061/dryad.3ts56) \n",
        "\n",
        "```\n",
        "Drewes, Jan; Zhu, Weina; Hu, Yingzhou; Hu, Xintian (2015), Data from: Smaller is better: drift in gaze measurements due to pupil dynamics, Dryad, Dataset, https://doi.org/10.5061/dryad.3ts56\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW2bwdhCyX7e",
        "colab_type": "code",
        "outputId": "5a40680c-1e8b-4996-a13b-3ce5a0f5cfa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "import scipy.io\n",
        "import scipy\n",
        "import numpy as np\n",
        "import csv\n",
        "from numpy import where\n",
        "# !wget https://datadryad.org/bitstream/handle/10255/dryad.71532/DrewesEtAl_PlosONE_2014.tar.gz #Old File\n",
        "!wget https://datadryad.org/stash/downloads/download_resource/1302__v1.zip\n",
        "!ls\n",
        "!unzip 1302__v1.zip\n",
        "!tar -xzf DrewesEtAl_PlosONE_2014.tar.gz\n",
        "mat = scipy.io.loadmat('/content/DrewesEtAl_PlosONE_2014.mat')\n",
        "\n",
        "\n",
        "#                  S1 = [1600,1200]       S2 = [1920, 1080]\n",
        "coorX = np.array([ [228,370,512,654,796], [470,655,840,1025,1210] ]) # S1, S2\n",
        "coorY = np.array([ [100,242,384,526,668], [155,340,525,710,895]   ]) # S1, S2\n",
        "# eye = 0 #Left Eye\n",
        "# eye = 3 #Right Eye\n",
        "nPar = 0\n",
        "calGrid = 0\n",
        "ligCond = 0\n",
        "repe = 0\n",
        "parti = 1\n",
        "allData = np.zeros([0,12])\n",
        "!mkdir Dataset\n",
        "!mkdir OutputTechniques\n",
        "!mkdir OutputMetrics\n",
        "\n",
        "# Variable for all percentiles\n",
        "pervar = 20"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-14 20:48:20--  https://datadryad.org/stash/downloads/download_resource/1302__v1.zip\n",
            "Resolving datadryad.org (datadryad.org)... 52.37.236.5, 50.112.214.6, 54.201.182.94\n",
            "Connecting to datadryad.org (datadryad.org)|52.37.236.5|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘1302__v1.zip’\n",
            "\n",
            "1302__v1.zip            [       <=>          ] 159.94M  31.1MB/s    in 14s     \n",
            "\n",
            "2019-10-14 20:48:34 (11.4 MB/s) - ‘1302__v1.zip’ saved [167711388]\n",
            "\n",
            "1302__v1.zip  sample_data\n",
            "Archive:  1302__v1.zip\n",
            "  inflating: DrewesEtAl_PlosONE_2014.tar.gz  \n",
            "  inflating: README_for_DrewesEtAl_PlosONE_2014.tar.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mXwlDV-Vosj",
        "colab_type": "text"
      },
      "source": [
        "## Modify dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jy6Am4huyoaL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b9dea5f8-8a8d-42f7-8fa9-be171e24ae59"
      },
      "source": [
        "print('Initiating...') \n",
        "for parti in range(0,39):   \n",
        "  fileName = '/content/Dataset/Part'+str(parti+1)+'.csv'\n",
        "  with open(fileName, 'a') as csvFile:\n",
        "    writer = csv.writer(csvFile, delimiter=';') \n",
        "    print(\"User\",parti+1, \"...\")\n",
        "    for ligCond in range(0,7): \n",
        "      for setPoint in range(0,25):\n",
        "        for repe in [0, 1, 2]:\n",
        "          cX = np.array( mat['Data']['Repeat'][0][parti][0][repe][0][0][ligCond][0]['Screen_X'] [0][setPoint]  )\n",
        "          cY = np.array( mat['Data']['Repeat'][0][parti][0][repe][0][0][ligCond][0]['Screen_Y'] [0][setPoint]  )\n",
        "          raw = np.array(mat['Data']['Repeat'][0][parti][0][repe][0][0][ligCond][0]['Epoch']    [0][setPoint]  )\n",
        "          \n",
        "          \n",
        "  #      OUTPUT FILE\n",
        "  #      0. Participant, 1. X calpoint, 2. Y calpoint,\n",
        "  #      3. X raw left eye, 4. Y raw left eye, 5. Calpoint, 6. X Timestamp, 7. Distance to left eye, \n",
        "  #      8. Repe+ligCond, 9.  X raw right eye, 10. Y raw right eye, 11. Distance to right eye\n",
        "          nMat = np.column_stack(( (parti+1)*np.ones(len(raw)) , \\\n",
        "                                  cX[0][0]*np.ones(len(raw)),\\\n",
        "                                  cY[0][0]*np.ones(len(raw)),\\\n",
        "                                  raw[:, 1], \\\n",
        "                                  raw[:, 2], \\\n",
        "                                  ((where(coorX==cX)[1] + (5*where(coorY==cY)[1])) + 1)*np.ones(len(raw) ),\\\n",
        "                                  raw[:, 0], \\\n",
        "                                  raw[:, 3], \\\n",
        "                                  np.full((len(raw),1), str('D'+str(repe)+str(ligCond))), \\\n",
        "                                  raw[:, 4], \\\n",
        "                                  raw[:, 5], \\\n",
        "                                  raw[:, 6]))\n",
        "          writer.writerows(nMat[:,:])\n",
        "  #         allData = np.append(allData, nMat, axis=0)\n",
        "      print(\"Light condition \",int(ligCond+1), \"... done\")\n",
        "  #     break\n",
        "  #   break\n",
        "    csvFile.close()\n",
        "  print('Done... ',ligCond+1,' light conditions for ', parti+1, ' user\\n\\n******')\n",
        "print('*-*-*- All done -*-*-*')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initiating...\n",
            "User 1 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  1  user\n",
            "\n",
            "******\n",
            "User 2 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  2  user\n",
            "\n",
            "******\n",
            "User 3 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  3  user\n",
            "\n",
            "******\n",
            "User 4 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  4  user\n",
            "\n",
            "******\n",
            "User 5 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  5  user\n",
            "\n",
            "******\n",
            "User 6 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  6  user\n",
            "\n",
            "******\n",
            "User 7 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  7  user\n",
            "\n",
            "******\n",
            "User 8 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  8  user\n",
            "\n",
            "******\n",
            "User 9 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  9  user\n",
            "\n",
            "******\n",
            "User 10 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  10  user\n",
            "\n",
            "******\n",
            "User 11 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  11  user\n",
            "\n",
            "******\n",
            "User 12 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  12  user\n",
            "\n",
            "******\n",
            "User 13 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  13  user\n",
            "\n",
            "******\n",
            "User 14 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  14  user\n",
            "\n",
            "******\n",
            "User 15 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  15  user\n",
            "\n",
            "******\n",
            "User 16 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  16  user\n",
            "\n",
            "******\n",
            "User 17 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  17  user\n",
            "\n",
            "******\n",
            "User 18 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  18  user\n",
            "\n",
            "******\n",
            "User 19 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  19  user\n",
            "\n",
            "******\n",
            "User 20 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  20  user\n",
            "\n",
            "******\n",
            "User 21 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  21  user\n",
            "\n",
            "******\n",
            "User 22 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  22  user\n",
            "\n",
            "******\n",
            "User 23 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  23  user\n",
            "\n",
            "******\n",
            "User 24 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  24  user\n",
            "\n",
            "******\n",
            "User 25 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  25  user\n",
            "\n",
            "******\n",
            "User 26 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  26  user\n",
            "\n",
            "******\n",
            "User 27 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  27  user\n",
            "\n",
            "******\n",
            "User 28 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  28  user\n",
            "\n",
            "******\n",
            "User 29 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  29  user\n",
            "\n",
            "******\n",
            "User 30 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  30  user\n",
            "\n",
            "******\n",
            "User 31 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  31  user\n",
            "\n",
            "******\n",
            "User 32 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  32  user\n",
            "\n",
            "******\n",
            "User 33 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  33  user\n",
            "\n",
            "******\n",
            "User 34 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  34  user\n",
            "\n",
            "******\n",
            "User 35 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  35  user\n",
            "\n",
            "******\n",
            "User 36 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  36  user\n",
            "\n",
            "******\n",
            "User 37 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  37  user\n",
            "\n",
            "******\n",
            "User 38 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  38  user\n",
            "\n",
            "******\n",
            "User 39 ...\n",
            "Light condition  1 ... done\n",
            "Light condition  2 ... done\n",
            "Light condition  3 ... done\n",
            "Light condition  4 ... done\n",
            "Light condition  5 ... done\n",
            "Light condition  6 ... done\n",
            "Light condition  7 ... done\n",
            "Done...  7  light conditions for  39  user\n",
            "\n",
            "******\n",
            "*-*-*- All done -*-*-*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1uloXHpEUHh",
        "colab_type": "text"
      },
      "source": [
        "## Obtain latest modified RANSAC Regressor from public repository\n",
        "Modified version of original sklearn RANSAC Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lanpoGIhchyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import numpy.linalg as lalg\n",
        "from numpy import where\n",
        "from itertools import compress\n",
        "import io\n",
        "import re\n",
        "import random\n",
        "from itertools import combinations, chain\n",
        "import math\n",
        "from math import log\n",
        "import itertools\n",
        "import csv\n",
        "import statistics\n",
        "from scipy.stats import poisson\n",
        "####\n",
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model.ransac import _dynamic_max_trials\n",
        "from sklearn.utils import check_random_state, check_array, check_consistent_length\n",
        "from sklearn.utils.validation import has_fit_parameter\n",
        "from sklearn.utils.random import sample_without_replacement\n",
        "\n",
        "\n",
        "\n",
        "class RANSACRegressor2(linear_model.RANSACRegressor):\n",
        "  \n",
        "  def fitSegm(self, X, y, segmList, sample_weight=None):\n",
        "    \n",
        "    merged = list(itertools.chain.from_iterable(segmList))\n",
        "  \n",
        "    \n",
        "    X = check_array(X, accept_sparse='csr')\n",
        "    y = check_array(y, ensure_2d=False)\n",
        "    check_consistent_length(X, y)\n",
        "\n",
        "    \n",
        "    \n",
        "    if self.base_estimator is not None:\n",
        "        base_estimator = clone(self.base_estimator)\n",
        "    else:\n",
        "        base_estimator = LinearRegression()\n",
        "\n",
        "    if self.min_samples is None:\n",
        "        # assume linear model by default\n",
        "        min_samples = X.shape[1] + 1 if len(segmList)<2 else X.shape[1]      #MINIMUM SAMPLES   \n",
        "    elif 0 < self.min_samples < 1:\n",
        "        min_samples = np.ceil(self.min_samples * X.shape[0])\n",
        "    elif self.min_samples >= 1:\n",
        "        if self.min_samples % 1 != 0:\n",
        "            raise ValueError(\"Absolute number of samples must be an \"\n",
        "                             \"integer value.\")\n",
        "        min_samples = self.min_samples\n",
        "    else:\n",
        "        raise ValueError(\"Value for `min_samples` must be scalar and \"\n",
        "                         \"positive.\")\n",
        "    if min_samples > X.shape[0]:\n",
        "        raise ValueError(\"`min_samples` may not be larger than number \"\n",
        "                         \"of samples: n_samples = %d.\" % (X.shape[0]))\n",
        "\n",
        "    if self.stop_probability < 0 or self.stop_probability > 1:\n",
        "        raise ValueError(\"`stop_probability` must be in range [0, 1].\")\n",
        "\n",
        "    if self.residual_threshold is None:\n",
        "        # MAD (median absolute deviation)\n",
        "        residual_threshold = np.percentile(np.abs(y - np.percentile(y,pervar)),pervar)\n",
        "    else:\n",
        "        residual_threshold = self.residual_threshold\n",
        "\n",
        "    if self.loss == \"absolute_loss\":\n",
        "        if y.ndim == 1:\n",
        "            loss_function = lambda y_true, y_pred: np.abs(y_true - y_pred)\n",
        "        else:\n",
        "            loss_function = lambda \\\n",
        "                y_true, y_pred: np.sum(np.abs(y_true - y_pred), axis=1)\n",
        "\n",
        "    elif self.loss == \"squared_loss\":\n",
        "        if y.ndim == 1:\n",
        "            loss_function = lambda y_true, y_pred: (y_true - y_pred) ** 2\n",
        "        else:\n",
        "            loss_function = lambda \\\n",
        "                y_true, y_pred: np.sum((y_true - y_pred) ** 2, axis=1)\n",
        "\n",
        "    elif callable(self.loss):\n",
        "        loss_function = self.loss\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            \"loss should be 'absolute_loss', 'squared_loss' or a callable.\"\n",
        "            \"Got %s. \" % self.loss)\n",
        "\n",
        "\n",
        "    random_state = check_random_state(self.random_state)\n",
        "\n",
        "    try:  # Not all estimator accept a random_state\n",
        "        base_estimator.set_params(random_state=random_state)\n",
        "    except ValueError:\n",
        "        pass\n",
        "\n",
        "    estimator_fit_has_sample_weight = has_fit_parameter(base_estimator,\n",
        "                                                        \"sample_weight\")\n",
        "    estimator_name = type(base_estimator).__name__\n",
        "    if (sample_weight is not None and not\n",
        "            estimator_fit_has_sample_weight):\n",
        "        raise ValueError(\"%s does not support sample_weight. Samples\"\n",
        "                         \" weights are only used for the calibration\"\n",
        "                         \" itself.\" % estimator_name)\n",
        "    if sample_weight is not None:\n",
        "        sample_weight = np.asarray(sample_weight)\n",
        "\n",
        "    n_inliers_best = 1\n",
        "    score_best = -np.inf\n",
        "    inlier_mask_best = None\n",
        "    X_inlier_best = None\n",
        "    y_inlier_best = None\n",
        "    aicc_ = None\n",
        "    self.n_skips_no_inliers_ = 0\n",
        "    self.n_skips_invalid_data_ = 0\n",
        "    self.n_skips_invalid_model_ = 0\n",
        "\n",
        "    \n",
        "       \n",
        "    # Generate a list of indices for each segment\n",
        "    size_sl = [len(s)-1 for s in segmList]\n",
        "    n_segments = len(size_sl)\n",
        "    \n",
        "    \n",
        "    # number of data samples\n",
        "    n_samples = X.shape[0] \n",
        "    sample_idxs = np.arange(n_samples)\n",
        "\n",
        "    n_samples, _ = X.shape\n",
        "    \n",
        "    \n",
        "    self.n_trials_ = 0\n",
        "    max_trials = self.max_trials\n",
        "    \n",
        " \n",
        "    \n",
        "    \n",
        "    while self.n_trials_ < max_trials:\n",
        "        self.n_trials_ += 1\n",
        "        if (self.n_skips_no_inliers_ + self.n_skips_invalid_data_ +\n",
        "                self.n_skips_invalid_model_) > self.max_skips:\n",
        "            break\n",
        "       \n",
        "\n",
        "\n",
        "        \n",
        "        # choose random sample set\n",
        "        ## antes:\n",
        "        ## subset_idxs = sample_without_replacement(n_samples, min_samples, random_state=random_state)\n",
        "        \n",
        "        \n",
        "        ## ahora:\n",
        "        subset_idx_entries = sample_without_replacement(n_segments, min_samples,\n",
        "                                                 random_state=random_state)\n",
        "        \n",
        "        \n",
        "        \n",
        "        subset_idxs = np.asarray([segmList[ss][random.randint(0, size_sl[ss])] \\\n",
        "                       for ss in subset_idx_entries])\n",
        "   \n",
        "    \n",
        "        \n",
        "        \n",
        "        X_subset = X[subset_idxs]\n",
        "        y_subset = y[subset_idxs]\n",
        "\n",
        "        # check if random sample set is valid\n",
        "        if (self.is_data_valid is not None\n",
        "                and not self.is_data_valid(X_subset, y_subset)):\n",
        "            self.n_skips_invalid_data_ += 1\n",
        "            continue        \n",
        "\n",
        "        # fit model for current random sample set\n",
        "        if sample_weight is None:\n",
        "          base_estimator.fit(X_subset, y_subset)\n",
        "        else:\n",
        "          base_estimator.fit(X_subset, y_subset, sample_weight=sample_weight[subset_idxs])\n",
        "\n",
        "        # check if estimated model is valid\n",
        "        if (self.is_model_valid is not None and not\n",
        "                self.is_model_valid(base_estimator, X_subset, y_subset)):\n",
        "            self.n_skips_invalid_model_ += 1\n",
        "            continue\n",
        "            \n",
        "        # check if estimated model is valid (ii)\n",
        "        y_pred_subset = base_estimator.predict(X_subset)\n",
        "        residuals_ii = loss_function(y_subset, y_pred_subset)\n",
        "        inlier_mask_subset_ii = residuals_ii < residual_threshold\n",
        "        \n",
        "        \n",
        "        if np.sum(inlier_mask_subset_ii)< X.shape[1]:\n",
        "          self.n_skips_invalid_model_ += 1\n",
        "          continue      \n",
        "        \n",
        "        \n",
        "        \n",
        "        ########################## Inlier evaluation\n",
        "      \n",
        "        # residuals of all data for current random sample model\n",
        "        y_pred = base_estimator.predict(X[merged])\n",
        "        residuals_subset = loss_function(y[merged], y_pred)\n",
        "        \n",
        "        # classify data into inliers and outliers\n",
        "        inlier_mask_subset = residuals_subset < residual_threshold \n",
        "        n_inliers_subset = np.sum(inlier_mask_subset)\n",
        "        if False:\n",
        "          print(f\"n_inliers_subset {n_inliers_subset} from {inlier_mask_subset.shape}\")\n",
        "          \n",
        "          \n",
        "          \n",
        "        # extract inlier data set        \n",
        "        inlier_idxs_subset = list(compress(merged, inlier_mask_subset))\n",
        "\n",
        "        X_inlier_subset = X[inlier_idxs_subset]\n",
        "        y_inlier_subset = y[inlier_idxs_subset]\n",
        "\n",
        "        if(False): # plain evaluation (basic approach) \n",
        "       \n",
        "\n",
        "          #check that the all points in sample are inliers\n",
        "          if n_inliers_subset < min_samples:\n",
        "              continue\n",
        "\n",
        "          # less inliers -> skip current random sample\n",
        "          if n_inliers_subset < n_inliers_best:\n",
        "              self.n_skips_no_inliers_ += 1\n",
        "              continue\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "          # score of inlier data set\n",
        "          score_subset = base_estimator.score(X_inlier_subset,\n",
        "                                              y_inlier_subset)\n",
        "\n",
        "\n",
        "          # same number of inliers but worse score -> skip current random\n",
        "          # sample\n",
        "          if (n_inliers_subset == n_inliers_best\n",
        "                  and score_subset <= score_best):\n",
        "              continue\n",
        "              \n",
        "              \n",
        "        else:   #evaluation for each calibration point\n",
        "          \n",
        "          \n",
        "          indScore =  0  # score that considers inliers of each calibration point\n",
        "          cc = 0\n",
        "          for sSeg,seg in zip(size_sl,segmList):\n",
        "            \n",
        "            c_seg = range(cc, sSeg+cc)\n",
        "            #print(seg)\n",
        "            #sys.exit(0)\n",
        "            cc+= sSeg\n",
        "\n",
        "            # classify data into inliers and outliers\n",
        "            nScore = np.sum(inlier_mask_subset[c_seg])\n",
        "            n_in_subset = nScore \n",
        "            \n",
        "            \n",
        "            indScore += poisson.cdf(nScore, 0.3*sSeg)\n",
        "            \n",
        "          \n",
        "          \n",
        "          if(indScore <= score_best):\n",
        "            continue\n",
        "          score_subset = indScore\n",
        "          \n",
        "          \n",
        "         \n",
        "          \n",
        "\n",
        "          \n",
        "    \n",
        "        # save current random sample as best sample\n",
        "        n_inliers_best = n_inliers_subset\n",
        "        score_best = score_subset\n",
        "        inlier_mask_best = inlier_mask_subset\n",
        "        X_inlier_best = X_inlier_subset\n",
        "        y_inlier_best = y_inlier_subset\n",
        "        \n",
        "\n",
        "        max_trials = min(\n",
        "            max_trials,\n",
        "            _dynamic_max_trials(n_inliers_best, n_samples,\n",
        "                                min_samples, self.stop_probability))\n",
        "\n",
        "\n",
        "        # break if sufficient number of inliers or score is reached\n",
        "        if n_inliers_best >= self.stop_n_inliers or \\\n",
        "                        score_best >= self.stop_score:\n",
        "            break\n",
        "\n",
        "  # if none of the iterations met the required criteria\n",
        "    if inlier_mask_best is None:\n",
        "        base_estimator.coef_=-999\n",
        "        if ((self.n_skips_no_inliers_ + self.n_skips_invalid_data_ +\n",
        "                self.n_skips_invalid_model_) > self.max_skips):\n",
        "            raise ValueError(\n",
        "                \"RANSAC skipped more iterations than `max_skips` without\"\n",
        "                \" finding a valid consensus set. Iterations were skipped\"\n",
        "                \" because each randomly chosen sub-sample failed the\"\n",
        "                \" passing criteria. See estimator attributes for\"\n",
        "                \" diagnostics (n_skips*).\")\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                \"RANSAC could not find a valid consensus set. All\"\n",
        "                \" `max_trials` iterations were skipped because each\"\n",
        "                \" randomly chosen sub-sample failed the passing criteria.\"\n",
        "                \" See estimator attributes for diagnostics (n_skips*).\")\n",
        "    else:\n",
        "        if (self.n_skips_no_inliers_ + self.n_skips_invalid_data_ +\n",
        "                self.n_skips_invalid_model_) > self.max_skips:\n",
        "            warnings.warn(\"RANSAC found a valid consensus set but exited\"\n",
        "                          \" early due to skipping more iterations than\"\n",
        "                          \" `max_skips`. See estimator attributes for\"\n",
        "                          \" diagnostics (n_skips*).\",\n",
        "                          ConvergenceWarning)\n",
        "    # estimate final model using all inliers\n",
        "        base_estimator.fit(X_inlier_best, y_inlier_best)    \n",
        "        self.estimator_ = base_estimator\n",
        "        self.inlier_mask_ = inlier_mask_best\n",
        "        return self\n",
        "##############\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQvsuRGscoge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# try:\n",
        "#   !rm -r /content/RANSACRegressor2\n",
        "#   !git clone https://github.com/jfernandoghe/RANSACRegressor2.git   \n",
        "# except:\n",
        "#   !git clone https://github.com/jfernandoghe/RANSACRegressor2.git        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p02oN6icvGU",
        "colab_type": "text"
      },
      "source": [
        "## Define and import modules, classes, functions and packages\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C16vD9GerTCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#@title\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import numpy.linalg as lalg\n",
        "from numpy import where\n",
        "import io\n",
        "import re\n",
        "import random\n",
        "from itertools import combinations, chain\n",
        "import math\n",
        "from math import log\n",
        "import itertools\n",
        "import csv\n",
        "import statistics\n",
        "import scipy\n",
        "\n",
        "def powerset(input_set, terms):\n",
        "    print('terms ', terms)\n",
        "    result = []\n",
        "    for size in range(terms + 1):\n",
        "        result += combinations(input_set, size)\n",
        "    return result\n",
        "      \n",
        "class TipoPrueba:\n",
        "  def __init__(self, pant, med, grouping): \n",
        "    self.pant = pant\n",
        "    self.med = med\n",
        "    self.grouping = grouping\n",
        "\n",
        "  def __repr__(self):\n",
        "    return \"Ajustar columnas de mediciones %s a las de pantalla %i con agrup %i\" \\\n",
        "  % (self.med, self.pant, self.grouping)\n",
        "\n",
        "def modeval_ransac(A,b):\n",
        "  parnum = A.ndim\n",
        "  numite = 100\n",
        "  AIC = 0\n",
        "  AICc = 0\n",
        "  MSE = 0\n",
        "  return AIC, AICc, MSE\n",
        "\n",
        "def c_pow(val, n):\n",
        "  return [ val**j  for j in range(0,n+1)]\n",
        "          \n",
        "          \n",
        "def allTerms(valXY, m, n):\n",
        "  v_m = c_pow(valXY[0], m)\n",
        "  v_n = c_pow(valXY[1], n)\n",
        "  mmax = max(m,n)\n",
        "  vals = [v_m[a]*v_n[b] for a in range(m+1) for b in range(n+1) if a+b<= mmax]\n",
        "  return vals\n",
        "\n",
        "def allSymbTerms(m, n):\n",
        "  sym_m = [ f'x^{j}' if j>1 else ('x' if j == 1 else '')  for j in range(0,m+1)]\n",
        "  sym_n = [ f'y^{j}' if j>1 else ('y' if j == 1 else '')  for j in range(0,n+1)]\n",
        "  mmax = max(m,n)\n",
        "  symb = [sym_m[a]+sym_n[b] if len(sym_m[a]+sym_n[b])>0 else '1' for a in range(m+1) for b in range(n+1) if a+b<= mmax] \n",
        "  return symb\n",
        "\n",
        "################\n",
        "#  Convert pixels to angle (in degrees)\n",
        "#     parameters: \n",
        "#     v1, pixel position\n",
        "#     smm, monitor size (mm)\n",
        "#     d,   eye distance\n",
        "def dst2Degree(v1, d, smm, spx):\n",
        "  # distance to screen center (in pixels)\n",
        "  v1c = v1 - spx/2 \n",
        "  \n",
        "  # convert pixel position in pixels to mm\n",
        "  v1mm = (v1c*smm)/spx\n",
        "  \n",
        "  \n",
        "  # calculate and return angle b \n",
        "  #      v1mm\n",
        "  #     ____ \n",
        "  #     |  /\n",
        "  #  d  |b/\n",
        "  #     |/ \n",
        "  return math.degrees( math.atan2(v1mm, d) )\n",
        "\n",
        "\n",
        "\n",
        "def removeSpurious(a, perc):\n",
        "  num = int(round(len(a) * perc/100.0))\n",
        "  for i in range(num):\n",
        "    a = np.delete(a, a.argmax()) \n",
        "  return a\n",
        "\n",
        "\n",
        "def removeSpuriousN(a, num):\n",
        "  for i in range(num):    \n",
        "    a = np.delete(a, a.argmax()) \n",
        "  return a\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkMlLiF0B9Sp",
        "colab_type": "text"
      },
      "source": [
        "## Columns in the .csv file\n",
        "0. Participant\n",
        "1. X calpoint\n",
        "2. Y calpoint\n",
        "3. X raw left eye\n",
        "4. Y raw left eye\n",
        "5. Calpoint\n",
        "6. X Timestamp\n",
        "7. Distance to left eye\n",
        "8. Repe+ligCond\n",
        "9. X raw right eye\n",
        "10. Y raw right eye\n",
        "11.Distance to right eye\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1RdW0cnc4_t",
        "colab_type": "text"
      },
      "source": [
        "## Main algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg_v4kx_p0Ck",
        "colab_type": "code",
        "outputId": "cc255159-41e2-46a9-dc8f-db2c332c1201",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#\n",
        "from google.colab import files\n",
        "import glob\n",
        "# from RANSACRegressor2 import RANSACRegressor2\n",
        "# Local Variables\n",
        "max_m = 3\n",
        "max_n = 2\n",
        "ax = ['x','y']\n",
        "lc = ['0', '12.5', '25', '37.5', '50', '75', '100']\n",
        "tr = ['First', 'Second', 'Third']\n",
        "mn = (max_m+1)*(max_n+1)\n",
        "max_degreeterm = 2\n",
        "T = (TipoPrueba(1, (3,4), 5), TipoPrueba(1, (9,10), 5))\n",
        "percData = 8\n",
        "coor = [ {228,370,512,654,796,100,242,384,526,668}, {470,655,840,1025,1210,155,340,525,710,895} ] #Coordinates of calibrations points\n",
        "res = [ [1600,1200], [1920, 1080] ] #Resolution in pixeles\n",
        "Smm = [ [487, 274], [508, 406.4] ] #Width and Height in mm\n",
        "\n",
        "for fname in glob.glob('/content/Dataset/Part*.csv'):\n",
        "  print('file name', fname)\n",
        "  df = pd.read_csv(fname, sep=';', names=['Participant', 'xp', 'yp', 'xl', 'yl', 'CalPoint', 'Timestamp', 'dL' ,'replig','xr','yr','dR'])\n",
        "  medx = (3, 4)\n",
        "  medx = (9, 10)\n",
        "\n",
        "# Eliminate NaN from dataframe  \n",
        "  df = df[df.xl != 0]\n",
        "  df = df[df.yl != 0]\n",
        "  df = df[df.xr != 0]\n",
        "  df = df[df.yr != 0]\n",
        "  df = df[df.xp != 0]\n",
        "  df = df[df.yp != 0]\n",
        "  df = df[df.CalPoint != 0]\n",
        "  df = df[df.Timestamp != 0]\n",
        "  df = df[df.dR != 0]\n",
        "  df = df[df.dL != 0]\n",
        "  df = df.fillna(0)\n",
        "  df = df.values\n",
        "  M = np.array(df)\n",
        "\n",
        "\n",
        "\n",
        "  #subsampling\n",
        "  M = M[::20, : ]\n",
        "  \n",
        "  \n",
        "  part = fname[17:-4]\n",
        "  print(\"************************************************************\")\n",
        "  print (part)\n",
        "  print(\"************************************************************\")\n",
        "  \n",
        "  for u in [0,1]: # Loop for each eye left and right      \n",
        "    for e in [0]: # Loop for each try    \n",
        "      for g in [5, 6]: # Loop for each light condition\n",
        "        \n",
        "        \n",
        "        print(f'axis {u} try {e} lighting condition {g} ' )\n",
        "        \n",
        "        mPart = M[where(M[:, 8] == 'D'+str(e)+str(g))]\n",
        "  #           mPart = M[where(M[:, 0] == part)] # Participant' data\n",
        "        bb = set(mPart[:,1])     #Ejemplo de X, índice [0] \n",
        "\n",
        "    #***************************************\n",
        "        if bool(bb & coor[0]):   #Check screentype\n",
        "          mon = 0\n",
        "        elif bool(bb & coor[1]):\n",
        "          mon = 1    \n",
        "    #***************************************\n",
        "\n",
        "\n",
        "        b = mPart[:, T[u].pant]\n",
        "        print(f\"Shape of b {b.shape}\")\n",
        "        d = mPart[:, T[u].med]   # XY data\n",
        "\n",
        "        group = mPart[:, T[u].grouping] \n",
        "        print (f' GROUP SIZE {group.size}')\n",
        "        segmList = [where(group==i)[0] for i in range(1,26)]\n",
        "        allTermStr = allSymbTerms (max_m, max_n)\n",
        "        s1 = np.asarray( [allTerms(xy, max_m, max_n) for xy in d], dtype='float' )\n",
        "\n",
        "\n",
        "        setA = {1, 17, 24, 13, 10, 19, 7, 21, 3} #Training set\n",
        "        setB = {i for i in range (25) } #Total set\n",
        "        setC = setB - setA #Validation set\n",
        "\n",
        "        if ( len(set( np.unique(mPart[:,5]).flatten().astype(int)-1 ).symmetric_difference(setB))==0 ):\n",
        "\n",
        "\n",
        "          segmLi1 = [segmList[i] for i in setA] # training-measurements\n",
        "          merged1 = list(itertools.chain.from_iterable(segmLi1))\n",
        "          segmLi2 = [segmList[i] for i in setC]   # test-measurements\n",
        "\n",
        "\n",
        "\n",
        "          # common approach\n",
        "          # (a) remove the first 10 percent of measurements (saccadic jumps SJ)\n",
        "          segmLstNSJ = [ lst[math.ceil(len(lst)/percData):] for lst in segmLi1] # list without saccadic_jumps\n",
        "          # (b) pick the median value\n",
        "          b_mm = [ statistics.median_high(b[lst]) for lst in segmLstNSJ]\n",
        "          d_mm = [ [statistics.median_high(d[lst,0]),statistics.median_high(d[lst,1])] for lst in segmLstNSJ] # XY data\n",
        "          s1_mm = np.asarray( [allTerms(xy, max_m, max_n) for xy in d_mm] )\n",
        "\n",
        "\n",
        "          # X-Models  0        1          2          3          4          5            6             7            8             9             10            11             12\n",
        "          modelsX = [[3,0], [3, 1, 0], [4, 3, 0], [6, 3, 0], [8, 3, 0], [6, 3, 0], [4, 3, 1, 0], [8, 6, 3, 0], [1, 6, 3, 0], [4, 6, 3, 0], [1, 8, 3, 0], [2, 8, 3, 0], [4, 8, 3, 0] ]\n",
        "\n",
        "          # Y-Models\n",
        "          modelsY = [[1, 0], [3, 1, 0], [4, 1, 0], [2, 1, 0], [1, 6, 0], [1, 4, 3, 0],[2, 1, 3, 0], [5, 3, 1, 0], [4, 1, 6, 0], [7, 6, 1, 0]] \n",
        "          models =np.array((modelsX,modelsY))\n",
        "\n",
        "          selStr = [\"AIC\", \"AICc\", \"KIC\", \"KICc\", \"AICF\", \"KICc\", \"RAIC\"] \n",
        "\n",
        "\n",
        "          # selectors explored: AIC, AICc, AKIC, AKICc, AICF, KICc, RAIC\n",
        "          errR2_4all = np.zeros((len(models[u]), len(setA)))\n",
        "\n",
        "          alp = 3\n",
        "          de = 60\n",
        "          rThreshold = 70 #(res[mon][t.grouping-5] *  (de*math.degrees(math.atan(alp))))/Smm[mon][t.grouping-5]  # Ahí le encargo!\n",
        "\n",
        "          print(f\" ========== rThreshold {rThreshold}\")\n",
        "\n",
        "          modelNum =0\n",
        "          errorsEv = np.zeros([len(setC)])\n",
        "          for model in models[u]: \n",
        "              maxBits = len(allTermStr)\n",
        "              if len(model)>0: # and len(model)<=max_degreeterm: # Select Models that accomplish certain parameter conditions (e.g., up to 5 parameters)\n",
        "                A = s1[:,model]\n",
        "\n",
        "\n",
        "                ######### training phase\n",
        "                ########################\n",
        "                allOk = True\n",
        "                try:\n",
        "                  #  Fit Simple Linear model (1)\n",
        "                  Am = np.array(A[merged1, :], dtype='float')\n",
        "                  bm = np.array(b[merged1], dtype='float')\n",
        "                  soln =  lalg.lstsq(Am, bm, rcond=None)\n",
        "                  theta = soln[0]\n",
        "                  residues = soln[1]\n",
        "\n",
        "\n",
        "                  # Fit linear model with point selection (median)  (2)\n",
        "                  A_mm = s1_mm[:,model]\n",
        "                  soln_mm =  lalg.lstsq(A_mm, b_mm, rcond=None)\n",
        "                  theta_mm = soln_mm[0]\n",
        "                  residues_mm = soln_mm[1]\n",
        "\n",
        "\n",
        "                  # Robustly fit linear model with RANSAC algorithm (Robust Linear Model) (3)\n",
        "                  ransac = RANSACRegressor2(residual_threshold=rThreshold)\n",
        "    #               ransac = RANSACRegressor2.RANSACRegressor2(residual_threshold=rThreshold) # For RANSACRegressor2 from github\n",
        "                  ransac.fitSegm(A, b, segmLi1)\n",
        "\n",
        "\n",
        "                  pos = 0\n",
        "                  for li in segmLi1:\n",
        "                    Avalid = np.array( [A[i, :] for i in li] )\n",
        "                    bvalid = np.array( [b[i] for i in li] )\n",
        "\n",
        "                    errR = ransac.predict(Avalid)-bvalid\n",
        "                    errR2 = np.multiply(errR, errR)\n",
        "                    errR2_4all[modelNum][pos] =  np.percentile(errR2, pervar)\n",
        "                    pos += 1\n",
        "\n",
        "\n",
        "                except ValueError as e:\n",
        "                  allOk = False\n",
        "                  print('errX', e)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                #end_try  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                ######### evaluation phase\n",
        "                ########################\n",
        "                pos1 = 0\n",
        "                betaR = np.zeros([len(setC)])\n",
        "                betaS = np.zeros([len(setC)])\n",
        "                betaC = np.zeros([len(setC)])\n",
        "\n",
        "\n",
        "                # Calculate and save errors\n",
        "\n",
        "                for li in segmLi2:\n",
        "                  Atest = np.array( [A[i, :] for i in li] )\n",
        "                  btest = np.array( [b[i] for i in li] )\n",
        "                  disL = np.array( [(mPart[i, 7])/10 for i in li] ) \n",
        "\n",
        "                  # estimation from a simple model (1)\n",
        "                  estimated =  np.matmul(Atest, theta)\n",
        "\n",
        "                  # estimation from saccadic_and_median filter (2)\n",
        "                  estimated_mm =  np.matmul(Atest, theta_mm)\n",
        "\n",
        "                  # estimation from Ransac (3)\n",
        "                  if allOk:    \n",
        "                    estimated_rr = ransac.predict(Atest) \n",
        "                  else:\n",
        "                    estimated_rr = 9999              \n",
        "\n",
        "    #               # error in DEGREES\n",
        "    #               if bool(bb & coor[0]):\n",
        "    #                 mon = 0\n",
        "    #               elif bool(bb & coor[1]):\n",
        "    #                 mon = 1\n",
        "\n",
        "\n",
        "                  ang  = [dst2Degree(btest[b], disL[b], Smm[mon][T[u].grouping-5], res[mon][T[u].grouping-5]) for b in range(len(disL))]\n",
        "                  ang = np.array(ang)\n",
        "                  ranAng = [dst2Degree(estimated_rr[b], disL[b], Smm[mon][T[u].grouping-5], res[mon][T[u].grouping-5]) for b in range(len(disL))]\n",
        "                  comAng = [dst2Degree(estimated[b],    disL[b], Smm[mon][T[u].grouping-5], res[mon][T[u].grouping-5]) for b in range(len(disL))]\n",
        "                  simAng = [dst2Degree(estimated_mm[b], disL[b], Smm[mon][T[u].grouping-5], res[mon][T[u].grouping-5]) for b in range(len(disL))]\n",
        "\n",
        "                  betaR[pos1] = np.percentile(abs(np.array(ranAng)- ang), pervar)\n",
        "                  betaS[pos1] = np.percentile(abs(np.array(comAng)- ang), pervar)\n",
        "                  betaC[pos1] = np.percentile(abs(np.array(simAng)- ang), pervar)\n",
        "\n",
        "\n",
        "\n",
        "                  pos1 += 1\n",
        "\n",
        "                #end_for\n",
        "\n",
        "                # Recall test  (05-2019)\n",
        "                foundR = sum(x < 2 for x in betaR)\n",
        "                foundC = sum(x < 2 for x in betaC)\n",
        "                #print(betaR)\n",
        "\n",
        "\n",
        "                usedTerms = [allTermStr[o] for o in model]\n",
        "\n",
        "                mR = np.percentile(betaR,pervar)            \n",
        "                mS = np.percentile(betaS,pervar)\n",
        "                mC = np.percentile(betaC,pervar)\n",
        "\n",
        "\n",
        "\n",
        "                print(\"modelNum\", modelNum )\n",
        "                print(usedTerms)\n",
        "\n",
        "                print(f'Ransac:  {mR}')\n",
        "                print(\"Simple: \", mS )\n",
        "                print(\"Common: \", mC )\n",
        "                print(\"-----\")\n",
        "                print(f'Found R(<3ang) {foundR}')\n",
        "                print(f'Found C(<3ang) {foundC}')\n",
        "\n",
        "\n",
        "\n",
        "                errorsEv[modelNum] = mR\n",
        "\n",
        "                with open('/content/OutputTechniques/'+fname[-10:], 'a') as csvFile:\n",
        "                  writer = csv.writer(csvFile, delimiter=';')\n",
        "\n",
        "                  # participant, model, strategy, modelName, value\n",
        "                  writer.writerow([part, modelNum, 0, usedTerms, mR])\n",
        "                  writer.writerow([part, modelNum, 1, usedTerms, mS])\n",
        "                  writer.writerow([part, modelNum, 2, usedTerms, mC])\n",
        "                csvFile.close()      \n",
        "                modelNum += 1\n",
        "\n",
        "\n",
        "          #print(errR2_4all)\n",
        "          ################### simulate selection\n",
        "          inAll = errR2_4all > rThreshold*rThreshold*1.2*1.2   \n",
        "          toDelete = min(inAll.sum(axis = 1))\n",
        "          #print(\"points to delete\", toDelete)\n",
        "          bestSelectorVal = np.ones(7) *  np.inf\n",
        "          selectorError = np.zeros(7)    \n",
        "\n",
        "          modelNum = 0\n",
        "          for model in models[u]: # evaluate each model      \n",
        "            k = len(model)\n",
        "            n = len(setA)-toDelete\n",
        "            if 2*k <= n:\n",
        "              rssI = removeSpuriousN(errR2_4all[modelNum], toDelete)\n",
        "              #print(\"rssI\", rssI)\n",
        "              sumRsc = np.sum(rssI)\n",
        "              c = rThreshold * rThreshold\n",
        "              sigmaHat = sumRsc/n\n",
        "              errRnorm =  rssI/sigmaHat\n",
        "              rhoError = [(r*r)/2 if abs(r)<=c else c*r*r- c*c/2  for r in errRnorm]\n",
        "\n",
        "              AIC = 2*(k) + n*math.log(sumRsc/n)\n",
        "              AICc = AIC + (2*k**2 + 2*k )/ (n - k - 1) if n>k+1 else -999\n",
        "              KIC = n*math.log(sumRsc/n) + 3*(k+1)\n",
        "              KICc = n*math.log(sumRsc/n) + (2*(k+1)*n)/(n-k-2) - n*scipy.special.digamma((n-k)/2)*((n-k)/2) + n* math.log(n/2) if n>k+2 else -999 # definir PSI\n",
        "              AKICc = n*math.log(sumRsc/n) + ((k+1)*(3*n-k-2))/(n-k-2) + k/(n-k)  if n>k and n>k+2 else -999\n",
        "              AICF = n/math.log(sumRsc/n) * ((n*k)/(n-k-2) + 2) if n>k+2 else -999\n",
        "              RAIC = 2*sum(rhoError) + 2*k\n",
        "\n",
        "              selectorValues = [AIC, AICc, KIC, KICc, AICF, KICc, RAIC]\n",
        "              for v in range (len(selectorValues)):\n",
        "                if selectorValues[v] < bestSelectorVal[v]:\n",
        "                  bestSelectorVal[v] = selectorValues[v]\n",
        "                  selectorError[v] = errorsEv[modelNum]\n",
        "\n",
        "            else:\n",
        "              AIC, AICc, KIC, KICc, AKICc, AICF, RAIC = -999,-999,-999,-999,-999,-999,-999\n",
        "\n",
        "            modelNum += 1\n",
        "\n",
        "          #print(\"selectorError\", selectorError)\n",
        "          with open('/content/OutputMetrics/'+fname[-10:], 'a') as csvFile:\n",
        "            writer = csv.writer(csvFile, delimiter=';')\n",
        "\n",
        "            ss = 0  \n",
        "            modelSe = np.where(selectorError[0]==errorsEv) if selectorError[0]!=0 else [-999]\n",
        "            print(\"Model Selected\", int(modelSe[0]))\n",
        "            for mSel in selectorError:\n",
        "                        # participant, model, strategy, modelName, value\n",
        "              writer.writerow([part, modelSe[0], ss+1000, selStr[ss], mSel])  # participant,  selNum,  selName, value\n",
        "              ss += 1\n",
        "          csvFile.close()\n",
        "        else:\n",
        "          print(\"Not enough calibration points\")\n",
        "        print('___________________________________________')\n",
        "      break\n",
        "    break\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file name /content/Dataset/Part14.csv\n",
            "************************************************************\n",
            "Part14\n",
            "************************************************************\n",
            "axis 0 try 0 lighting condition 5 \n",
            "Shape of b (1247,)\n",
            " GROUP SIZE 1247\n",
            " ========== rThreshold 70\n",
            "modelNum 0\n",
            "['x', '1']\n",
            "Ransac:  0.16155892669529096\n",
            "Simple:  6.375451309334127\n",
            "Common:  0.5203898513260796\n",
            "-----\n",
            "Found R(<3ang) 13\n",
            "Found C(<3ang) 11\n",
            "modelNum 1\n",
            "['x', 'y', '1']\n",
            "Ransac:  0.15432188232154972\n",
            "Simple:  4.201907152654374\n",
            "Common:  0.5269601995128752\n",
            "-----\n",
            "Found R(<3ang) 16\n",
            "Found C(<3ang) 13\n",
            "modelNum 2\n",
            "['xy', 'x', '1']\n",
            "Ransac:  0.1959898014691135\n",
            "Simple:  5.058748310915275\n",
            "Common:  0.626730327293626\n",
            "-----\n",
            "Found R(<3ang) 14\n",
            "Found C(<3ang) 11\n",
            "modelNum 3\n",
            "['x^2', 'x', '1']\n",
            "Ransac:  0.14158900376842923\n",
            "Simple:  6.35252137601301\n",
            "Common:  0.34609216581836366\n",
            "-----\n",
            "Found R(<3ang) 11\n",
            "Found C(<3ang) 11\n",
            "modelNum 4\n",
            "['x^3', 'x', '1']\n",
            "Ransac:  0.2481386130443596\n",
            "Simple:  6.601897298194935\n",
            "Common:  0.44792722030718013\n",
            "-----\n",
            "Found R(<3ang) 11\n",
            "Found C(<3ang) 11\n",
            "modelNum 5\n",
            "['x^2', 'x', '1']\n",
            "Ransac:  0.14158900376842923\n",
            "Simple:  6.35252137601301\n",
            "Common:  0.34609216581836366\n",
            "-----\n",
            "Found R(<3ang) 11\n",
            "Found C(<3ang) 11\n",
            "modelNum 6\n",
            "['xy', 'x', 'y', '1']\n",
            "Ransac:  0.07238157720877042\n",
            "Simple:  5.044264153953052\n",
            "Common:  0.4366440214695366\n",
            "-----\n",
            "Found R(<3ang) 16\n",
            "Found C(<3ang) 16\n",
            "modelNum 7\n",
            "['x^3', 'x^2', 'x', '1']\n",
            "Ransac:  0.3559119335943606\n",
            "Simple:  0.8077036338547103\n",
            "Common:  0.2353866262979565\n",
            "-----\n",
            "Found R(<3ang) 11\n",
            "Found C(<3ang) 11\n",
            "modelNum 8\n",
            "['y', 'x^2', 'x', '1']\n",
            "Ransac:  0.15342854444371812\n",
            "Simple:  4.0830651757858965\n",
            "Common:  0.3328136297108245\n",
            "-----\n",
            "Found R(<3ang) 14\n",
            "Found C(<3ang) 12\n",
            "modelNum 9\n",
            "['xy', 'x^2', 'x', '1']\n",
            "Ransac:  0.3630593532832421\n",
            "Simple:  3.9436544535118028\n",
            "Common:  0.7456533460130231\n",
            "-----\n",
            "Found R(<3ang) 12\n",
            "Found C(<3ang) 9\n",
            "modelNum 10\n",
            "['y', 'x^3', 'x', '1']\n",
            "Ransac:  0.1454328470142201\n",
            "Simple:  4.282464575130338\n",
            "Common:  0.34600181924774637\n",
            "-----\n",
            "Found R(<3ang) 14\n",
            "Found C(<3ang) 12\n",
            "modelNum 11\n",
            "['y^2', 'x^3', 'x', '1']\n",
            "Ransac:  0.09424499256274431\n",
            "Simple:  4.292387264109384\n",
            "Common:  0.5460506632740803\n",
            "-----\n",
            "Found R(<3ang) 14\n",
            "Found C(<3ang) 12\n",
            "modelNum 12\n",
            "['xy', 'x^3', 'x', '1']\n",
            "Ransac:  0.3441816509609666\n",
            "Simple:  4.375723793874679\n",
            "Common:  0.6083069554038446\n",
            "-----\n",
            "Found R(<3ang) 12\n",
            "Found C(<3ang) 10\n",
            "Model Selected 6\n",
            "___________________________________________\n",
            "axis 0 try 0 lighting condition 6 \n",
            "Shape of b (1249,)\n",
            " GROUP SIZE 1249\n",
            " ========== rThreshold 70\n",
            "modelNum 0\n",
            "['x', '1']\n",
            "Ransac:  0.355689315510314\n",
            "Simple:  3.4711138881114976\n",
            "Common:  0.29716183924536455\n",
            "-----\n",
            "Found R(<3ang) 11\n",
            "Found C(<3ang) 11\n",
            "modelNum 1\n",
            "['x', 'y', '1']\n",
            "Ransac:  0.17647364495686022\n",
            "Simple:  2.283743920816282\n",
            "Common:  0.20868101575111242\n",
            "-----\n",
            "Found R(<3ang) 16\n",
            "Found C(<3ang) 16\n",
            "modelNum 2\n",
            "['xy', 'x', '1']\n",
            "Ransac:  0.1496265526919956\n",
            "Simple:  1.4102256222743308\n",
            "Common:  0.17722607521322403\n",
            "-----\n",
            "Found R(<3ang) 13\n",
            "Found C(<3ang) 13\n",
            "modelNum 3\n",
            "['x^2', 'x', '1']\n",
            "Ransac:  0.46851419187314886\n",
            "Simple:  5.162570893393831\n",
            "Common:  0.35148925544579446\n",
            "-----\n",
            "Found R(<3ang) 12\n",
            "Found C(<3ang) 12\n",
            "modelNum 4\n",
            "['x^3', 'x', '1']\n",
            "Ransac:  0.37274883884246324\n",
            "Simple:  4.950434373132051\n",
            "Common:  0.3660690244697221\n",
            "-----\n",
            "Found R(<3ang) 12\n",
            "Found C(<3ang) 12\n",
            "modelNum 5\n",
            "['x^2', 'x', '1']\n",
            "Ransac:  0.353759014300735\n",
            "Simple:  5.162570893393831\n",
            "Common:  0.35148925544579446\n",
            "-----\n",
            "Found R(<3ang) 12\n",
            "Found C(<3ang) 12\n",
            "modelNum 6\n",
            "['xy', 'x', 'y', '1']\n",
            "Ransac:  0.17373981847095765\n",
            "Simple:  2.4009424107839226\n",
            "Common:  0.18497249409532657\n",
            "-----\n",
            "Found R(<3ang) 16\n",
            "Found C(<3ang) 16\n",
            "modelNum 7\n",
            "['x^3', 'x^2', 'x', '1']\n",
            "Ransac:  0.20313016234427578\n",
            "Simple:  0.5199251720664961\n",
            "Common:  0.4412174287514077\n",
            "-----\n",
            "Found R(<3ang) 12\n",
            "Found C(<3ang) 11\n",
            "modelNum 8\n",
            "['y', 'x^2', 'x', '1']\n",
            "Ransac:  0.11202728156213482\n",
            "Simple:  1.213070722696972\n",
            "Common:  0.17067679664857138\n",
            "-----\n",
            "Found R(<3ang) 15\n",
            "Found C(<3ang) 15\n",
            "modelNum 9\n",
            "['xy', 'x^2', 'x', '1']\n",
            "Ransac:  0.21110125963470666\n",
            "Simple:  0.5909525624611647\n",
            "Common:  0.22068783262123193\n",
            "-----\n",
            "Found R(<3ang) 14\n",
            "Found C(<3ang) 13\n",
            "modelNum 10\n",
            "['y', 'x^3', 'x', '1']\n",
            "Ransac:  0.15875037278613463\n",
            "Simple:  1.4257594871178918\n",
            "Common:  0.18881801181244384\n",
            "-----\n",
            "Found R(<3ang) 16\n",
            "Found C(<3ang) 15\n",
            "modelNum 11\n",
            "['y^2', 'x^3', 'x', '1']\n",
            "Ransac:  0.14894076550299523\n",
            "Simple:  1.073645602457681\n",
            "Common:  0.14998292784331113\n",
            "-----\n",
            "Found R(<3ang) 16\n",
            "Found C(<3ang) 15\n",
            "modelNum 12\n",
            "['xy', 'x^3', 'x', '1']\n",
            "Ransac:  0.23596135569118673\n",
            "Simple:  0.18438908840160764\n",
            "Common:  0.20088067350717867\n",
            "-----\n",
            "Found R(<3ang) 14\n",
            "Found C(<3ang) 13\n",
            "Model Selected 1\n",
            "___________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHxyc-LkD2j2",
        "colab_type": "text"
      },
      "source": [
        "## TEST CODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miTdNwhKbZr5",
        "colab_type": "code",
        "outputId": "519bcc26-df58-4f92-cbf7-9435bc76a262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# X-Models  0        1          2          3          4          5            6             7            8             9             10            11             12\n",
        "modelsX = [[3,0], [3, 1, 0], [4, 3, 0], [6, 3, 0], [8, 3, 0], [6, 3, 0], [4, 3, 1, 0], [8, 6, 3, 0], [1, 6, 3, 0], [4, 6, 3, 0], [1, 8, 3, 0], [2, 8, 3, 0], [4, 8, 3, 0] ]\n",
        "\n",
        "# Y-Models\n",
        "modelsY = [[1, 0], [3, 1, 0], [4, 1, 0], [2, 1, 0], [1, 6, 0], [1, 4, 3, 0],[2, 1, 3, 0], [5, 3, 1, 0], [4, 1, 6, 0], [7, 6, 1, 0]] \n",
        "models =np.array((modelsX,modelsY))\n",
        "print(models[0][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}